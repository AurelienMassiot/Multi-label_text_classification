{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re, string\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "TOXIC_COMMENT_DATA_PATH = Path().cwd().parent / 'data'\n",
    "print(TOXIC_COMMENT_DATA_PATH)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(toxic_comment_data_path):\n",
    "    train_df = pd.read_csv(toxic_comment_data_path / 'train.csv')\n",
    "    test_df = pd.read_csv(toxic_comment_data_path / 'test.csv')\n",
    "    test_labels_df = pd.read_csv(toxic_comment_data_path / 'test_labels.csv')\n",
    "    return train_df, test_df, test_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = train_df.comment_text.str.len()\n",
    "lens.mean(), lens.std(), lens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre de classe par réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsums=train_df.iloc[:,2:].sum(axis=1)\n",
    "x = rowsums.value_counts().sort_index()\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = sns.barplot(x.index, x.values, alpha=0.8)\n",
    "plt.title(\"Multiple tags per comment\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('# of tags ', fontsize=12)\n",
    "\n",
    "#adding the text labels\n",
    "rects = ax.patches\n",
    "labels = x.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "COMMENT = 'comment_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape,len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(train_df, test_df):\n",
    "    train_df['none'] = 1-train_df[LABELS].max(axis=1)\n",
    "    train_df[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "    test_df[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = data_preprocessing(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TF_IDF_Vectorizer(train_df,test_df, comment):    \n",
    "    vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "                   min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "                   smooth_idf=1, sublinear_tf=1 )\n",
    "    trn_term_doc = vec.fit_transform(train_df[comment])\n",
    "    test_term_doc = vec.transform(test_df[comment])\n",
    "    return trn_term_doc, test_term_doc, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_term_doc, test_term_doc, vec = TF_IDF_Vectorizer(train_df,test_df, COMMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive bayes\n",
    "def pr(x,y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mdl_cross_val_score(X, y):\n",
    "    r = np.log(pr(X, 1,y) / pr(X, 0,y))\n",
    "    classifier = LogisticRegression()\n",
    "    X_nb = X.multiply(r)\n",
    "    cv_score = np.mean(cross_val_score(classifier, X_nb, y, cv=3, scoring='roc_auc'))\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fit_mdl(x,y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(x,1,y) / pr(x,0,y))\n",
    "    m = LogisticRegression()\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_classifier_for_each_theme_and_get_its_naiveB_coef(df, train_term_doc,labels):\n",
    "    all_classifiers_and_r = []\n",
    "    for idx, theme in enumerate(labels):\n",
    "        print('fit', theme)\n",
    "        target = df[theme]\n",
    "        classifier,r = get_fit_mdl(train_term_doc, target)\n",
    "        all_classifiers_and_r.append([classifier,r])\n",
    "    return all_classifiers_and_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "test_x = test_term_doc\n",
    "x, test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Val Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_CV_score_for_each_class(df,labels,term_doc):\n",
    "    scores = []\n",
    "    for label in labels:\n",
    "        target = df[label].values\n",
    "        X = term_doc\n",
    "\n",
    "        cv_score = get_mdl_cross_val_score(X, target)\n",
    "        scores.append(cv_score)\n",
    "        print('CV score for class {} is {}'.format(label, cv_score))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = compute_CV_score_for_each_class(train_df,LABELS,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "y = train_df[LABELS]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_classifiers_and_NB_coeff = fit_classifier_for_each_theme_and_get_its_naiveB_coef(y_train,x_train, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction_and_feature_importance(x_test, classifiers_and_coef, labels):\n",
    "    preds = np.zeros((x_test.shape[0], len(labels)))\n",
    "    feature_importance = []\n",
    "    for idx, theme in enumerate(labels):\n",
    "        classifier,r = classifiers_and_coef[idx][0],classifiers_and_coef[idx][1]\n",
    "        preds[:,idx] = classifier.predict_proba(x_test.multiply(r))[:,1]\n",
    "        coefficients = classifier.coef_[0]\n",
    "        coefficients = 100.0 * (coefficients / coefficients.max())\n",
    "        feature_importance.append(coefficients)\n",
    "    return preds, feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction x_val (test labellisé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = get_prediction_and_feature_importance(x_val, all_classifiers_and_NB_coeff, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction pour le test_df (non labellisé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds_unlabelized = get_prediction_and_feature_importance(test_x, all_classifiers_and_NB_coeff, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "article_multi_label",
   "language": "python",
   "name": "article_multi_label"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}